<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Xinhao Zhong</title><meta name="author" content="Xinhao Zhong"><meta name="copyright" content="Xinhao Zhong"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta property="og:type" content="website">
<meta property="og:title" content="Xinhao Zhong">
<meta property="og:url" content="http://example.com/page/3/index.html">
<meta property="og:site_name" content="Xinhao Zhong">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/avatar.jpg">
<meta property="article:author" content="Xinhao Zhong">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/avatar.jpg"><link rel="shortcut icon" href="/img/crucifix.png"><link rel="canonical" href="http://example.com/page/3/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Xinhao Zhong',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2024-11-07 12:44:32'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.0.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">65</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">16</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('/img/index_img.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="Xinhao Zhong"><span class="site-name">Xinhao Zhong</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">Xinhao Zhong</h1></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/04/12/%E9%9D%A2%E8%AF%95%E7%9B%B8%E5%85%B3/%E6%89%8B%E6%92%95%E4%BB%A3%E7%A0%81/" title="手撕代码">手撕代码</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-04-12T11:58:08.000Z" title="发表于 2024-04-12 19:58:08">2024-04-12</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E9%9D%A2%E8%AF%95%E7%9B%B8%E5%85%B3/">面试相关</a></span></div><div class="content">手撕注意力机制12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import torchimport torch.nn as nnimport mathimport torch.nn.functional as Fclass MultiheadAttention(nn.Module):    def __init__(self, d_model: int, heads: int = 8):        super().__init__()        self.d_model = d_model        self.heads = heads        self.d_k = self.d_model // self.heads        self.q_proj = nn.Linear(d_model, d_model)        self.k_proj = nn.Linear(d_model, d_model)        self.v_ ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/04/04/NLP/NLP%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/" title="NLP评价指标">NLP评价指标</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-04-04T06:58:41.000Z" title="发表于 2024-04-04 14:58:41">2024-04-04</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span></div><div class="content">BLEU(Bilingual Evaluation Understudy)
定义：BLEU是一种用于评估机器翻译质量的指标，它通过比较机器翻译输出和一组参考翻译之间的n-gram重叠来评分。

计算方式：BLEU分数是通过计算机器翻译输出和参考翻译之间的n-gram精确匹配度，并通过短语长度惩罚因子来调整得到的。BLEU分数的范围从0到1，其中1表示完美的匹配。

应用场景：BLEU主要用于机器翻译任务，但也可用于其他文本生成任务，如文本摘要。





Rouge(Recall-Oriented Understudy for Gisting Evaluation)
定义：ROUGE是一组用于评估自动文摘和机器翻译质量的指标，它主要关注召回率，但也考虑精确率。

计算方式：ROUGE包括多种指标，如ROUGE-N（基于n-gram的重叠）、ROUGE-L（基于最长公共子序列）和ROUGE-W（加权最长公共子序列）。每种指标都有其特定的计算方式，主要关注生成的文本和参考文本之间的重叠程度。

应用场景：ROUGE广泛用于自动文摘和机器翻译任务，特别是在需要考虑文本的整体相似性时。



 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/04/01/%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6/python%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6/" title="Python开发框架">Python开发框架</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-04-01T03:28:48.000Z" title="发表于 2024-04-01 11:28:48">2024-04-01</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6/">开发框架</a></span></div><div class="content">简介
FastAPI 是一个用于构建 API 的现代、快速（高性能）的 web 框架，使用 Python 3.8+ 并基于标准的 Python 类型提示。

安装教程
安装fastapi

1pip install fastapi


安装uvicorn：Uvicorn是一个基于ASGI（Asynchronous Server Gateway Interface）的异步Web服务器，用于运行异步Python web应用程序。它是由编写FastAPI框架的开发者设计的，旨在提供高性能和低延迟的Web服务

1pip install uvicorn

快速入门123456789101112131415161718from fastapi import FastAPIapp = FastAPI()@app.get(&quot;/&quot;)async def index():    return &#123;&quot;message&quot;: &quot;Hello World&quot;&#125;@app.get(&quot;/info&quot;)async def info( ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/03/29/%E5%A4%A7%E6%A8%A1%E5%9E%8B/PaLM/" title="PaLM">PaLM</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-03-29T03:27:58.000Z" title="发表于 2024-03-29 11:27:58">2024-03-29</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B/">大模型</a></span></div><div class="content">重要结论
模型规模带来的模型能力的提升还远没有达到上限；

通过思维链（chain of thought prompting）方式让模型生成自然语言来解释其预测的方式对模型是有益的，以便更好地理解模型为什么做出某种预测。即，模型的生成(而不仅仅是理解)功能可以非常有益，甚至对于建模为分类预测或回归的任务也是如此，这些任务通常不需要大量的语言生成。

侧重提高参数规模和训练效率，同GPT-3相比：

模型规模不同；
训练语料不同，包含多语言；
模型训练不同，基于Pathways，一种新的可以在数千个加速器芯片上高效地训练超大型神经网络的机器学习系统对模型训练进行加速；



背景
大模型的性能来自于以下几个方面：增加模型的深度和宽度；增加训练模型的tokens数量；在来源更多样化的更干净的数据集上进行训练；在不增加计算成本的情况下，通过稀疏激活模块增加模型容量。本文从以上几个方面着手，旨在训练一个规模更大，性能更好的LLM。

实现细节数据集
训练语料包含780B个token。模型在数据集上训练一个epoch。该数据集混合了过滤后的网页、书、维基百科、新闻文章、源代码和社交媒体对话。

 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/03/29/%E5%A4%A7%E6%A8%A1%E5%9E%8B/Bloom/" title="the BigScience Large Open-science Open-access Multilingual Language Model (BLOOM)">the BigScience Large Open-science Open-access Multilingual Language Model (BLOOM)</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-03-29T03:27:48.000Z" title="发表于 2024-03-29 11:27:48">2024-03-29</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B/">大模型</a></span></div><div class="content">重要结论
在训练语料中包含代码可以提高模型处理自然语言任务的准确率。
侧重训练一个规模和 GPT-3 一样的多语言语言模型


使用了ALiBi Positional Embeddings 位置嵌入
在嵌入层后面加了一层 LayerNorm 层，好处是训练时提升了稳定性；坏处是会影响到推断是零样本学习的泛化能力
Tokenizer和GPT-2不同，自己训练了一个；
训练语料不同，包含多语言和编程语言；
预训练任务不同，除了无条件生成任务外，在指令数据集上进行了多任务微调；
模型训练不同，采用Megatron-DeepSpeed并行技术对模型训练进行加速；

背景
以往的大规模语言模型，例如GPT，GPT-2，GPT-3主要是基于英语语料训练的。 本文旨在基于一个包含46种自然语言和13种编程语言的语料库，训练一个规模和GPT-3相当的多语言语言模型。为此，本文首先在多语言数据集上进行模型预训练，然后在指令数据集上微调模型。

实现细节数据集

预训练数据处理过程如图所示。从网上获取的源数据中包含大量的非自然语言，例如预处理错误、SEO页面或垃圾邮件。第一步是去除这些非自然语言。为此，本 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/03/27/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/PyTorch/" title="PyTorch">PyTorch</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-03-27T04:01:28.000Z" title="发表于 2024-03-27 12:01:28">2024-03-27</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/">分布式训练框架</a></span></div><div class="content">简介
PyTorch 分为 torch.nn.parallel.DataParallel (DP) 和 torch.nn.parallel.DistributedDataParallel (DDP)。

DDP与DP的区别
DP是单进程多线程的，只能在单机上工作；DDP是多进程的，可以在多级多卡上工作。DP通常比DDP慢，主要原因有：
DP是单进程的，受到GIL的限制；
DP每个step都需要拷贝模型，以及划分数据和收集输出；


DDP可以与模型并行相结合；
DP的通信成本随着卡数线性增长，DDP支持Ring-AllReduce，通信成本是固定的。

DP模式
DP是较简单的一种数据并行方式，直接将模型复制到多个GPU上并行计算，每个GPU计算batch中的一部分数据，各自完成前向和反向后，将梯度汇总到主GPU上。其基本流程：
加载模型、数据至内存；
创建DP模型；
DP模型的forward过程：
一个batch的数据均分到不同device上；
为每个device复制一份模型；
至此，每个device上有模型和一份数据，并行进行前向传播；
收集各个device上的输出；


每个de ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/03/16/%E5%90%91%E9%87%8F%E6%A3%80%E7%B4%A2/%E5%90%91%E9%87%8F%E6%A3%80%E7%B4%A2/" title="向量检索">向量检索</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-03-16T10:28:32.000Z" title="发表于 2024-03-16 18:28:32">2024-03-16</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%90%91%E9%87%8F%E6%A3%80%E7%B4%A2/">向量检索</a></span></div><div class="content">引言
向量检索，即根据一个向量Q从海量的向量库中寻找TopK个与Q最相似或者距离最近的向量，其在工业中有着广泛的应用场景，比如图像检索、文本语义检索以及推荐系统中基于User与Item的Embedding向量召回等。


向量嵌入
Vector Embedding 是由 AI 模型（例如大型语言模型 LLM）生成的，它会根据不同的算法生成高维度的向量数据，代表着数据的不同特征，这些特征代表了数据的不同维度。例如，对于文本，这些特征可能包括词汇、语法、语义、情感、情绪、主题、上下文等。对于音频，这些特征可能包括音调、节奏、音高、音色、音量、语音、音乐等。实际上，只要维度够多，我们就能够将所有的事物区分开来，世间万物都可以用一个多维坐标系来表示，它们都在一个高维的特征空间中对应着一个坐标点。

例如对于目前来说，文本向量可以通过 OpenAI 的 text-embedding-ada-002 模型生成，图像向量可以通过 clip-vit-base-patch32 模型生成，而音频向量可以通过 wav2vec2-base-960h 模型生成。这些向量都是通过 AI 模型生成的，所以它们都是具 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/03/16/NLP/XLNet/" title="XLNet">XLNet</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-03-16T07:33:52.000Z" title="发表于 2024-03-16 15:33:52">2024-03-16</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span></div><div class="content">论文链接
排列语言模型（Permutation Language Modeling）
XLNET结合自回归语言模型和自编码语言模型的优点，提出了排列语言模型

我们对所有token进行排列组合。通过不同的排列，在预测某一个 token 的时候，总会有不同的排列能考虑到所有 token 的上下文信息。注意的是，实际在预训练时，并非真的重新排列，而是利用attention mask的思想来近似实现不同的排列。



双流自注意力
根据上面的思想，又引出了一个问题，例如 I love New York 这四个token，现在有两个序列 1 -&gt; 2 -&gt; 3 -&gt; 4 和 1 -&gt; 2 -&gt; 4 -&gt; 3，假设已经知道前面两个 token 是 I love，要预测下一个token，很明显，在两个序列中，下一个token为New的概率都是一样的，这是非常不合理的，因为New作为位置3和位置4的概率应该是不一样的。因此，作者提出了一种双流自注意力。

Query Stream：只能看到当前的位置信息，不能看到当前token的编码
Content Stream： ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/03/16/NLP/BGE/" title="BGE">BGE</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-03-16T05:51:26.000Z" title="发表于 2024-03-16 13:51:26">2024-03-16</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Embedding-Model/">Embedding Model</a></span></div><div class="content">前言
Foundation Model有两个代表，一个是 Large Language Model，另一个是 Embedding Model。

前者聚焦文本空间，其形式化功能为text -&gt; text；后者聚焦向量空间，其功能为text -&gt; embedding。转为向量能做些什么呢？比较常见的使用场景包括retrieval（如检索知识库、检索Tool）、clustering（聚类）、classification（分类）等。

在中文世界，智源研究院的 BGE 是比较有名的开源 embedding model


方法论
BGE从两个方面来达成这个目标：

数据方面，兼顾scale、diversity、quality这三个维度，这是通用embedding模型能训练出来的前提；
训练策略方面，论文使用3阶段训练策略，从pre-training 到 general-purpose fine-tuning 再到 task-specific fine-tuning；前两个阶段是保证通用性的基石，最后一个阶段则在保持通用的基础上，进一步精进下游任务的效果。



数据方面
模型方面 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/03/11/NLP/Transformer-XL/" title="Transformer-XL">Transformer-XL</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-03-11T08:51:57.000Z" title="发表于 2024-03-11 16:51:57">2024-03-11</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span></div><div class="content">论文链接
前言
Transformer-XL（extra long）是为了进一步提升 Transformer 建模长期依赖的能力。它的核心算法包含两部分：片段递归机制（segment-level recurrence）和相对位置编码机制 (relative positional encoding)。

Transformer-XL带来的提升包括：1. 捕获长期依赖的能力；2. 解决了上下文碎片问题（context segmentation problem）；3. 提升模型的预测速度和准确率。


片段递归
Transformer-XL 在训练的时候是以固定长度的片段的形式进行输入的，Transformer-XL 的上一个片段的状态会被缓存下来，然后在计算当前段的时候再重复使用上个时间片的隐层状态。因为上个片段的特征在当前片段进行了重复使用，这也就赋予了 Transformer-XL 建模更长期的依赖的能力。



另一个好处是带来的推理速度的提升，对比Transformer的自回归架构每次只能前进一个时间片，Transfomer-XL的推理过程通过直接复用上一个片段的表示而不是从头计算 ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/2/#content-inner"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/#content-inner">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/#content-inner">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/#content-inner">7</a><a class="extend next" rel="next" href="/page/4/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Xinhao Zhong</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">65</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">16</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Twxwx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">A Little Bit More</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/10/23/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%BB%93%E5%90%88%E5%A4%A7%E6%A8%A1%E5%9E%8B/" title="知识图谱结合大模型">知识图谱结合大模型</a><time datetime="2024-10-23T12:27:01.000Z" title="发表于 2024-10-23 20:27:01">2024-10-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/10/09/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%98%E5%9C%A8%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/" title="大模型存在问题及解决方法">大模型存在问题及解决方法</a><time datetime="2024-10-09T15:33:49.000Z" title="发表于 2024-10-09 23:33:49">2024-10-09</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/29/CV/DINO/" title="DINO">DINO</a><time datetime="2024-09-29T08:39:17.000Z" title="发表于 2024-09-29 16:39:17">2024-09-29</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/22/NLP/RNN%E5%92%8CLSTM/" title="RNN和LSTM">RNN和LSTM</a><time datetime="2024-09-22T08:36:24.000Z" title="发表于 2024-09-22 16:36:24">2024-09-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/21/%E6%90%9C%E5%B9%BF%E6%8E%A8/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95-%E7%B2%BE%E6%8E%92/" title="推荐算法-精排">推荐算法-精排</a><time datetime="2024-09-21T15:25:58.000Z" title="发表于 2024-09-21 23:25:58">2024-09-21</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            <a class="card-more-btn" href="/categories/" title="查看更多">
    <i class="fas fa-angle-right"></i></a>
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/CV/"><span class="card-category-list-name">CV</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Embedding-Model/"><span class="card-category-list-name">Embedding Model</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/NLP/"><span class="card-category-list-name">NLP</span><span class="card-category-list-count">10</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/"><span class="card-category-list-name">分布式训练框架</span><span class="card-category-list-count">2</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%90%91%E9%87%8F%E6%A3%80%E7%B4%A2/"><span class="card-category-list-name">向量检索</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"><span class="card-category-list-name">基础语法</span><span class="card-category-list-count">2</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%A4%9A%E6%A8%A1%E6%80%81/"><span class="card-category-list-name">多模态</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3/"><span class="card-category-list-name">大数据相关</span><span class="card-category-list-count">1</span></a></li>
            </ul></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span><a class="card-more-btn" href="/archives/" title="查看更多">
    <i class="fas fa-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/10/"><span class="card-archive-list-date">十月 2024</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/09/"><span class="card-archive-list-date">九月 2024</span><span class="card-archive-list-count">6</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/08/"><span class="card-archive-list-date">八月 2024</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/07/"><span class="card-archive-list-date">七月 2024</span><span class="card-archive-list-count">3</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/06/"><span class="card-archive-list-date">六月 2024</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/05/"><span class="card-archive-list-date">五月 2024</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/04/"><span class="card-archive-list-date">四月 2024</span><span class="card-archive-list-count">6</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/03/"><span class="card-archive-list-date">三月 2024</span><span class="card-archive-list-count">13</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">65</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2024-11-07T04:44:32.269Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By Xinhao Zhong</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>